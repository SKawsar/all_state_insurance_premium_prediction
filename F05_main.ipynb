{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# K-fold cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# to save the models\n",
    "import pickle\n",
    "\n",
    "# to remove unnecessary warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to ensure clear background of the visualization and enhance visibility\n",
    "# sns.set_context('talk')\n",
    "\n",
    "# pip install ipynb\n",
    "from ipynb.fs.full.F01_data_preprocessing_functions import feature_set, variance_threshold_selector\n",
    "from ipynb.fs.full.F03_ML_functions import cv_result, GBRegressor_with_target_transformation\n",
    "from ipynb.fs.full.F03_ML_functions import error_comparison_with_target_transformation\n",
    "from ipynb.fs.full.F03_ML_functions import GBRegressor_without_target_transformation\n",
    "from ipynb.fs.full.F03_ML_functions import error_comparison_without_target_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the train dataset as pandas dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10  ...     cont6  \\\n",
       "id                                                     ...             \n",
       "1     A    B    A    B    A    A    A    A    B     A  ...  0.718367   \n",
       "2     A    B    A    A    A    A    A    A    B     B  ...  0.438917   \n",
       "5     A    B    A    A    B    A    A    A    B     B  ...  0.289648   \n",
       "10    B    B    A    B    A    A    A    A    B     A  ...  0.440945   \n",
       "11    A    B    A    B    A    A    A    A    B     B  ...  0.178193   \n",
       "\n",
       "       cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "id                                                                      \n",
       "1   0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "2   0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "5   0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "10  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "11  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "      cont14     loss  \n",
       "id                     \n",
       "1   0.714843  2213.18  \n",
       "2   0.304496  1283.60  \n",
       "5   0.774425  3005.09  \n",
       "10  0.602642   939.85  \n",
       "11  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in the train data =  188318\n",
      "No. of columns in the train data =  131\n"
     ]
    }
   ],
   "source": [
    "train_ = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# set the 'id' column as index\n",
    "train_ = train_.set_index('id')\n",
    "\n",
    "n_samples_train = train_.shape[0]\n",
    "display(train_.head())\n",
    "print(\"No. of rows in the train data = \", n_samples_train)\n",
    "print(\"No. of columns in the train data = \", train_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the target variable =  (188318, 1)\n",
      "Shape of the train data after removing the target variable =  (188318, 130)\n"
     ]
    }
   ],
   "source": [
    "# separating the target variable from the train data\n",
    "y = train_[['loss']]\n",
    "\n",
    "# removing the target variable from the train data\n",
    "train_ = train_.drop('loss', axis=1)\n",
    "\n",
    "print(\"Shape of the target variable = \", y.shape)\n",
    "print(\"Shape of the train data after removing the target variable = \", train_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the test dataset as pandas dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10  ...     cont5  \\\n",
       "id                                                     ...             \n",
       "4     A    B    A    A    A    A    A    A    B     A  ...  0.281143   \n",
       "6     A    B    A    B    A    A    A    A    B     A  ...  0.836443   \n",
       "9     A    B    A    B    B    A    B    A    B     B  ...  0.718531   \n",
       "12    A    A    A    A    B    A    A    A    A     A  ...  0.397069   \n",
       "15    B    A    A    A    A    B    A    A    A     A  ...  0.302678   \n",
       "\n",
       "       cont6     cont7    cont8    cont9   cont10    cont11    cont12  \\\n",
       "id                                                                      \n",
       "4   0.466591  0.317681  0.61229  0.34365  0.38016  0.377724  0.369858   \n",
       "6   0.482425  0.443760  0.71330  0.51890  0.60401  0.689039  0.675759   \n",
       "9   0.212308  0.325779  0.29758  0.34365  0.30529  0.245410  0.241676   \n",
       "12  0.369930  0.342355  0.40028  0.33237  0.31480  0.348867  0.341872   \n",
       "15  0.398862  0.391833  0.23688  0.43731  0.50556  0.359572  0.352251   \n",
       "\n",
       "      cont13    cont14  \n",
       "id                      \n",
       "4   0.704052  0.392562  \n",
       "6   0.453468  0.208045  \n",
       "9   0.258586  0.297232  \n",
       "12  0.592264  0.555955  \n",
       "15  0.301535  0.825823  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in the test data =  125546\n",
      "No. of columns in the test data =  130\n"
     ]
    }
   ],
   "source": [
    "test_ = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# set the 'id' column as index\n",
    "test_ = test_.set_index('id')\n",
    "\n",
    "display(test_.head())\n",
    "print(\"No. of rows in the test data = \", test_.shape[0])\n",
    "print(\"No. of columns in the test data = \", test_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in the entire dataset =  313864\n",
      "No. of columns in the entire dataset =  130\n"
     ]
    }
   ],
   "source": [
    "# combining the train and test data for basic data preprocessing\n",
    "df = pd.concat([train_, test_])\n",
    "\n",
    "print(\"No. of rows in the entire dataset = \", df.shape[0])\n",
    "print(\"No. of columns in the entire dataset = \", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values and check the data type of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313864 entries, 1 to 587634\n",
      "Data columns (total 130 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat1    313864 non-null  object \n",
      " 1   cat2    313864 non-null  object \n",
      " 2   cat3    313864 non-null  object \n",
      " 3   cat4    313864 non-null  object \n",
      " 4   cat5    313864 non-null  object \n",
      " 5   cat6    313864 non-null  object \n",
      " 6   cat7    313864 non-null  object \n",
      " 7   cat8    313864 non-null  object \n",
      " 8   cat9    313864 non-null  object \n",
      " 9   cat10   313864 non-null  object \n",
      " 10  cat11   313864 non-null  object \n",
      " 11  cat12   313864 non-null  object \n",
      " 12  cat13   313864 non-null  object \n",
      " 13  cat14   313864 non-null  object \n",
      " 14  cat15   313864 non-null  object \n",
      " 15  cat16   313864 non-null  object \n",
      " 16  cat17   313864 non-null  object \n",
      " 17  cat18   313864 non-null  object \n",
      " 18  cat19   313864 non-null  object \n",
      " 19  cat20   313864 non-null  object \n",
      " 20  cat21   313864 non-null  object \n",
      " 21  cat22   313864 non-null  object \n",
      " 22  cat23   313864 non-null  object \n",
      " 23  cat24   313864 non-null  object \n",
      " 24  cat25   313864 non-null  object \n",
      " 25  cat26   313864 non-null  object \n",
      " 26  cat27   313864 non-null  object \n",
      " 27  cat28   313864 non-null  object \n",
      " 28  cat29   313864 non-null  object \n",
      " 29  cat30   313864 non-null  object \n",
      " 30  cat31   313864 non-null  object \n",
      " 31  cat32   313864 non-null  object \n",
      " 32  cat33   313864 non-null  object \n",
      " 33  cat34   313864 non-null  object \n",
      " 34  cat35   313864 non-null  object \n",
      " 35  cat36   313864 non-null  object \n",
      " 36  cat37   313864 non-null  object \n",
      " 37  cat38   313864 non-null  object \n",
      " 38  cat39   313864 non-null  object \n",
      " 39  cat40   313864 non-null  object \n",
      " 40  cat41   313864 non-null  object \n",
      " 41  cat42   313864 non-null  object \n",
      " 42  cat43   313864 non-null  object \n",
      " 43  cat44   313864 non-null  object \n",
      " 44  cat45   313864 non-null  object \n",
      " 45  cat46   313864 non-null  object \n",
      " 46  cat47   313864 non-null  object \n",
      " 47  cat48   313864 non-null  object \n",
      " 48  cat49   313864 non-null  object \n",
      " 49  cat50   313864 non-null  object \n",
      " 50  cat51   313864 non-null  object \n",
      " 51  cat52   313864 non-null  object \n",
      " 52  cat53   313864 non-null  object \n",
      " 53  cat54   313864 non-null  object \n",
      " 54  cat55   313864 non-null  object \n",
      " 55  cat56   313864 non-null  object \n",
      " 56  cat57   313864 non-null  object \n",
      " 57  cat58   313864 non-null  object \n",
      " 58  cat59   313864 non-null  object \n",
      " 59  cat60   313864 non-null  object \n",
      " 60  cat61   313864 non-null  object \n",
      " 61  cat62   313864 non-null  object \n",
      " 62  cat63   313864 non-null  object \n",
      " 63  cat64   313864 non-null  object \n",
      " 64  cat65   313864 non-null  object \n",
      " 65  cat66   313864 non-null  object \n",
      " 66  cat67   313864 non-null  object \n",
      " 67  cat68   313864 non-null  object \n",
      " 68  cat69   313864 non-null  object \n",
      " 69  cat70   313864 non-null  object \n",
      " 70  cat71   313864 non-null  object \n",
      " 71  cat72   313864 non-null  object \n",
      " 72  cat73   313864 non-null  object \n",
      " 73  cat74   313864 non-null  object \n",
      " 74  cat75   313864 non-null  object \n",
      " 75  cat76   313864 non-null  object \n",
      " 76  cat77   313864 non-null  object \n",
      " 77  cat78   313864 non-null  object \n",
      " 78  cat79   313864 non-null  object \n",
      " 79  cat80   313864 non-null  object \n",
      " 80  cat81   313864 non-null  object \n",
      " 81  cat82   313864 non-null  object \n",
      " 82  cat83   313864 non-null  object \n",
      " 83  cat84   313864 non-null  object \n",
      " 84  cat85   313864 non-null  object \n",
      " 85  cat86   313864 non-null  object \n",
      " 86  cat87   313864 non-null  object \n",
      " 87  cat88   313864 non-null  object \n",
      " 88  cat89   313864 non-null  object \n",
      " 89  cat90   313864 non-null  object \n",
      " 90  cat91   313864 non-null  object \n",
      " 91  cat92   313864 non-null  object \n",
      " 92  cat93   313864 non-null  object \n",
      " 93  cat94   313864 non-null  object \n",
      " 94  cat95   313864 non-null  object \n",
      " 95  cat96   313864 non-null  object \n",
      " 96  cat97   313864 non-null  object \n",
      " 97  cat98   313864 non-null  object \n",
      " 98  cat99   313864 non-null  object \n",
      " 99  cat100  313864 non-null  object \n",
      " 100 cat101  313864 non-null  object \n",
      " 101 cat102  313864 non-null  object \n",
      " 102 cat103  313864 non-null  object \n",
      " 103 cat104  313864 non-null  object \n",
      " 104 cat105  313864 non-null  object \n",
      " 105 cat106  313864 non-null  object \n",
      " 106 cat107  313864 non-null  object \n",
      " 107 cat108  313864 non-null  object \n",
      " 108 cat109  313864 non-null  object \n",
      " 109 cat110  313864 non-null  object \n",
      " 110 cat111  313864 non-null  object \n",
      " 111 cat112  313864 non-null  object \n",
      " 112 cat113  313864 non-null  object \n",
      " 113 cat114  313864 non-null  object \n",
      " 114 cat115  313864 non-null  object \n",
      " 115 cat116  313864 non-null  object \n",
      " 116 cont1   313864 non-null  float64\n",
      " 117 cont2   313864 non-null  float64\n",
      " 118 cont3   313864 non-null  float64\n",
      " 119 cont4   313864 non-null  float64\n",
      " 120 cont5   313864 non-null  float64\n",
      " 121 cont6   313864 non-null  float64\n",
      " 122 cont7   313864 non-null  float64\n",
      " 123 cont8   313864 non-null  float64\n",
      " 124 cont9   313864 non-null  float64\n",
      " 125 cont10  313864 non-null  float64\n",
      " 126 cont11  313864 non-null  float64\n",
      " 127 cont12  313864 non-null  float64\n",
      " 128 cont13  313864 non-null  float64\n",
      " 129 cont14  313864 non-null  float64\n",
      "dtypes: float64(14), object(116)\n",
      "memory usage: 313.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# if the number of features > 100, \n",
    "# pandas .info() method needs some modification to show the deatils of all the features\n",
    "pd.options.display.max_info_columns = 150\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, there are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of categorical features in the dataset =  116\n",
      "no. of continuous features in the dataset =  14\n"
     ]
    }
   ],
   "source": [
    "# list of categorical features\n",
    "cat_cols = feature_set(df, 'O')\n",
    "\n",
    "# print(\"list of categorical features = \", cat_cols)\n",
    "print(\"no. of categorical features in the dataset = \", np.size(cat_cols))\n",
    "\n",
    "# list of continuous features\n",
    "cont_cols = feature_set(df, 'float64')\n",
    "\n",
    "# print(\"list of continuous features = \", cont_cols)\n",
    "print(\"no. of continuous features in the dataset = \", np.size(cont_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding of the categorical features\n",
    "Based on your suggestion, I encoded the categorical variables ordinally. Though from the dataset it's not sure how the unique values of each feature are related. \n",
    "\n",
    "In ordinal encoding, each unique category value is assigned an integer value and it's easily reversible..\n",
    "For example, 'A' is 0, 'B' is 1, and 'C' is 2.\n",
    "\n",
    "I also tried with the one-hot encoding but it increases the number of features a lot. I tried PCA to reduce the dimensionality but the runtime was very high and the model performance was not satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...  \\\n",
       "id                                                               ...   \n",
       "1    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "2    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "5    0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "10   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "11   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "\n",
       "       cont5     cont6     cont7    cont8    cont9   cont10    cont11  \\\n",
       "id                                                                      \n",
       "1   0.310061  0.718367  0.335060  0.30260  0.67135  0.83510  0.569745   \n",
       "2   0.885834  0.438917  0.436585  0.60087  0.35127  0.43919  0.338312   \n",
       "5   0.397069  0.289648  0.315545  0.27320  0.26076  0.32446  0.381398   \n",
       "10  0.422268  0.440945  0.391128  0.31796  0.32128  0.44467  0.327915   \n",
       "11  0.704268  0.178193  0.247408  0.24564  0.22089  0.21230  0.204687   \n",
       "\n",
       "      cont12    cont13    cont14  \n",
       "id                                \n",
       "1   0.594646  0.822493  0.714843  \n",
       "2   0.366307  0.611431  0.304496  \n",
       "5   0.373424  0.195709  0.774425  \n",
       "10  0.321570  0.605077  0.602642  \n",
       "11  0.202213  0.246011  0.432606  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the entire dataset =  313864\n",
      "number of columns in the entire dataset =  130\n",
      "ordinal encoder doesn't create new features. So, the number of features in the dataset remain the same\n"
     ]
    }
   ],
   "source": [
    "# instantiate the encoder\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "# using a loop to encode all categorical features ordinally\n",
    "for col in cat_cols:\n",
    "    df[col] = enc.fit_transform(df[col].values.reshape(-1,1))\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# number of columns in the entire dataset\n",
    "n_features = df.shape[1]\n",
    "\n",
    "print(\"number of rows in the entire dataset = \", df.shape[0])\n",
    "print(\"number of columns in the entire dataset = \", n_features)\n",
    "\n",
    "print(\"ordinal encoder doesn't create new features. So, the number of features in the dataset remain the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage reduction: to speed up the training and testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage before the data type conversion =  313.69 MB\n",
      "memory usage after the data type conversion =  80.22 MB\n",
      "So, the data type conversion from float64 to float16 has reduced the memory usage by  74.43 %\n"
     ]
    }
   ],
   "source": [
    "# memory usage before the data type conversion\n",
    "memory_usage_before = np.round(df.memory_usage(deep=True).sum()/(1024*1024), 2)\n",
    "\n",
    "# data type conversion from 'float64' to 'float16'\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype('float16')\n",
    "\n",
    "# memory usage after the data type conversion\n",
    "memory_usage_after = np.round(df.memory_usage(deep=True).sum()/(1024*1024), 2)\n",
    "\n",
    "# percentage of memory usage reduction\n",
    "usage_reduction = np.round(((memory_usage_before-memory_usage_after)*100)/memory_usage_before,2)\n",
    "\n",
    "print(\"memory usage before the data type conversion = \", memory_usage_before, \"MB\")\n",
    "print(\"memory usage after the data type conversion = \", memory_usage_after, \"MB\")\n",
    "print(\"So, the data type conversion from float64 to float16 has reduced the memory usage by \", usage_reduction, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the features with lower variance\n",
    "Features which have variance < 0.01 will be removed to reduce the system complexity. After changing the variance threshold with different values, it's confirm that removing these low variance features doesn't hamper the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>0.718262</td>\n",
       "      <td>0.334961</td>\n",
       "      <td>0.302490</td>\n",
       "      <td>0.671387</td>\n",
       "      <td>0.834961</td>\n",
       "      <td>0.569824</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885742</td>\n",
       "      <td>0.438965</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>0.601074</td>\n",
       "      <td>0.351318</td>\n",
       "      <td>0.439209</td>\n",
       "      <td>0.338379</td>\n",
       "      <td>0.366211</td>\n",
       "      <td>0.611328</td>\n",
       "      <td>0.304443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.289551</td>\n",
       "      <td>0.315430</td>\n",
       "      <td>0.273193</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>0.381348</td>\n",
       "      <td>0.373535</td>\n",
       "      <td>0.195679</td>\n",
       "      <td>0.774414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422363</td>\n",
       "      <td>0.440918</td>\n",
       "      <td>0.391113</td>\n",
       "      <td>0.317871</td>\n",
       "      <td>0.321289</td>\n",
       "      <td>0.444580</td>\n",
       "      <td>0.327881</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.602539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>0.178223</td>\n",
       "      <td>0.247437</td>\n",
       "      <td>0.245605</td>\n",
       "      <td>0.220947</td>\n",
       "      <td>0.212280</td>\n",
       "      <td>0.204712</td>\n",
       "      <td>0.202271</td>\n",
       "      <td>0.245972</td>\n",
       "      <td>0.432617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...  \\\n",
       "id                                                               ...   \n",
       "1    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "2    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "5    0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "10   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "11   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "\n",
       "       cont5     cont6     cont7     cont8     cont9    cont10    cont11  \\\n",
       "id                                                                         \n",
       "1   0.310059  0.718262  0.334961  0.302490  0.671387  0.834961  0.569824   \n",
       "2   0.885742  0.438965  0.436523  0.601074  0.351318  0.439209  0.338379   \n",
       "5   0.396973  0.289551  0.315430  0.273193  0.260742  0.324463  0.381348   \n",
       "10  0.422363  0.440918  0.391113  0.317871  0.321289  0.444580  0.327881   \n",
       "11  0.704102  0.178223  0.247437  0.245605  0.220947  0.212280  0.204712   \n",
       "\n",
       "      cont12    cont13    cont14  \n",
       "id                                \n",
       "1   0.594727  0.822266  0.714844  \n",
       "2   0.366211  0.611328  0.304443  \n",
       "5   0.373535  0.195679  0.774414  \n",
       "10  0.321533  0.604980  0.602539  \n",
       "11  0.202271  0.245972  0.432617  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of features in the dataset =  130\n",
      "Number of remaining features in the dataset =  101\n",
      "Number of features reduced =  29\n",
      "Percentage of features reduced =  22 %\n"
     ]
    }
   ],
   "source": [
    "df = variance_threshold_selector(df, 0.01)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Actual number of features in the dataset = \", n_features)\n",
    "\n",
    "# after removing the features with lower variance\n",
    "n_features_var_threshold = df.shape[1]\n",
    "print(\"Number of remaining features in the dataset = \", n_features_var_threshold)\n",
    "\n",
    "# percentage of reduction in features\n",
    "p_reduced_features = int((n_features - n_features_var_threshold)*100/n_features)\n",
    "print(\"Number of features reduced = \", n_features - n_features_var_threshold)\n",
    "print(\"Percentage of features reduced = \", p_reduced_features, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the train and inference set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 101) (125546, 101)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train = df.iloc[:n_samples_train,:]\n",
    "test = df.iloc[n_samples_train:,:]\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# check if the number of samples remain same as the initial train and test set\n",
    "print(train.shape[0] == train_.shape[0])\n",
    "print(test.shape[0] == test_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>0.718262</td>\n",
       "      <td>0.334961</td>\n",
       "      <td>0.302490</td>\n",
       "      <td>0.671387</td>\n",
       "      <td>0.834961</td>\n",
       "      <td>0.569824</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885742</td>\n",
       "      <td>0.438965</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>0.601074</td>\n",
       "      <td>0.351318</td>\n",
       "      <td>0.439209</td>\n",
       "      <td>0.338379</td>\n",
       "      <td>0.366211</td>\n",
       "      <td>0.611328</td>\n",
       "      <td>0.304443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.289551</td>\n",
       "      <td>0.315430</td>\n",
       "      <td>0.273193</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>0.381348</td>\n",
       "      <td>0.373535</td>\n",
       "      <td>0.195679</td>\n",
       "      <td>0.774414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422363</td>\n",
       "      <td>0.440918</td>\n",
       "      <td>0.391113</td>\n",
       "      <td>0.317871</td>\n",
       "      <td>0.321289</td>\n",
       "      <td>0.444580</td>\n",
       "      <td>0.327881</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.602539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>0.178223</td>\n",
       "      <td>0.247437</td>\n",
       "      <td>0.245605</td>\n",
       "      <td>0.220947</td>\n",
       "      <td>0.212280</td>\n",
       "      <td>0.204712</td>\n",
       "      <td>0.202271</td>\n",
       "      <td>0.245972</td>\n",
       "      <td>0.432617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...  \\\n",
       "id                                                               ...   \n",
       "1    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "2    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "5    0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "10   1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "11   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    1.0  ...   \n",
       "\n",
       "       cont5     cont6     cont7     cont8     cont9    cont10    cont11  \\\n",
       "id                                                                         \n",
       "1   0.310059  0.718262  0.334961  0.302490  0.671387  0.834961  0.569824   \n",
       "2   0.885742  0.438965  0.436523  0.601074  0.351318  0.439209  0.338379   \n",
       "5   0.396973  0.289551  0.315430  0.273193  0.260742  0.324463  0.381348   \n",
       "10  0.422363  0.440918  0.391113  0.317871  0.321289  0.444580  0.327881   \n",
       "11  0.704102  0.178223  0.247437  0.245605  0.220947  0.212280  0.204712   \n",
       "\n",
       "      cont12    cont13    cont14  \n",
       "id                                \n",
       "1   0.594727  0.822266  0.714844  \n",
       "2   0.366211  0.611328  0.304443  \n",
       "5   0.373535  0.195679  0.774414  \n",
       "10  0.321533  0.604980  0.602539  \n",
       "11  0.202271  0.245972  0.432617  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.466553</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.612305</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.380127</td>\n",
       "      <td>0.377686</td>\n",
       "      <td>0.369873</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>0.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836426</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>0.443848</td>\n",
       "      <td>0.713379</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>0.208008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.212280</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>0.297607</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>0.245361</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.258545</td>\n",
       "      <td>0.297119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.369873</td>\n",
       "      <td>0.342285</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>0.332275</td>\n",
       "      <td>0.314697</td>\n",
       "      <td>0.348877</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.592285</td>\n",
       "      <td>0.556152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302734</td>\n",
       "      <td>0.398926</td>\n",
       "      <td>0.391846</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0.437256</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.359619</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>0.301514</td>\n",
       "      <td>0.825684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...  \\\n",
       "id                                                               ...   \n",
       "4    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "6    0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0    0.0  ...   \n",
       "9    0.0   1.0   0.0   1.0   1.0   0.0   1.0   0.0   1.0    1.0  ...   \n",
       "12   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
       "15   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0  ...   \n",
       "\n",
       "       cont5     cont6     cont7     cont8     cont9    cont10    cont11  \\\n",
       "id                                                                         \n",
       "4   0.281250  0.466553  0.317627  0.612305  0.343750  0.380127  0.377686   \n",
       "6   0.836426  0.482422  0.443848  0.713379  0.519043  0.604004  0.688965   \n",
       "9   0.718750  0.212280  0.325684  0.297607  0.343750  0.305176  0.245361   \n",
       "12  0.396973  0.369873  0.342285  0.400391  0.332275  0.314697  0.348877   \n",
       "15  0.302734  0.398926  0.391846  0.236938  0.437256  0.505371  0.359619   \n",
       "\n",
       "      cont12    cont13    cont14  \n",
       "id                                \n",
       "4   0.369873  0.704102  0.392578  \n",
       "6   0.675781  0.453369  0.208008  \n",
       "9   0.241699  0.258545  0.297119  \n",
       "12  0.341797  0.592285  0.556152  \n",
       "15  0.352295  0.301514  0.825684  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train and test set for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150654, 101) (37664, 101) (150654, 1) (37664, 1)\n"
     ]
    }
   ],
   "source": [
    "# training size = 80%, test size = 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection method: Recursive Feature Elimination (RFE)\n",
    "\n",
    "RFE is an efficient approach for eliminating features from a training dataset and it selects those features in a training dataset that are most relevant in predicting the target variable. There are two important configuration options when using RFE: the choice in the number of features to select (n_features_to_select) and the choice of the algorithm used to help choose features (estimator). \n",
    "\n",
    "RFE works by searching for a subset of features by starting with all features in the training dataset and successfully removing features until the desired number remains. This is achieved by fitting the given machine learning algorithm used in the core of the model, ranking features by importance, discarding the least important features, and re-fitting the model. This process is repeated until a specified number of features remains.\n",
    "\n",
    "I have used Gradient Boosting Regressor and done some experiment by varying the n_features_to_select from 101 to 50. Finally, I found that, starting with 101 features and removing 5 least important features at each iteration, up to n_features_to_select=60, the model performance remain the same.\n",
    "\n",
    "ref: https://machinelearningmastery.com/rfe-feature-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 61 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=GradientBoostingRegressor(random_state=42),\n",
       "    n_features_to_select=60, step=5, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=GradientBoostingRegressor(random_state=42), n_features_to_select=60, step=5, verbose=1)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the RFE model\n",
    "pickle.dump(rfe, open(\"rfe.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the RFE model\n",
    "rfe = pickle.load(open(\"rfe.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining features after Variance Threshold method and RFE =  60\n",
      "Finally selected features for training =  Index(['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat9', 'cat10',\n",
      "       'cat12', 'cat23', 'cat25', 'cat26', 'cat27', 'cat36', 'cat37', 'cat38',\n",
      "       'cat44', 'cat52', 'cat53', 'cat57', 'cat71', 'cat72', 'cat73', 'cat75',\n",
      "       'cat76', 'cat77', 'cat79', 'cat80', 'cat81', 'cat82', 'cat87', 'cat88',\n",
      "       'cat90', 'cat92', 'cat94', 'cat95', 'cat96', 'cat100', 'cat101',\n",
      "       'cat103', 'cat105', 'cat108', 'cat109', 'cat111', 'cat113', 'cat114',\n",
      "       'cat115', 'cat116', 'cont1', 'cont2', 'cont3', 'cont6', 'cont7',\n",
      "       'cont8', 'cont9', 'cont11', 'cont12', 'cont13', 'cont14'],\n",
      "      dtype='object')\n",
      "Number of features reduced after Variance Thresholding and RFE=  70\n",
      "Percentage of total features reduced =  53 %\n"
     ]
    }
   ],
   "source": [
    "# list of selected features after the recursive feature elimination (RFE)\n",
    "rfe_cols = X_train.columns[rfe.support_]\n",
    "\n",
    "n_features_rfe = rfe_cols.shape[0]\n",
    "print(\"Number of remaining features after Variance Threshold method and RFE = \", n_features_rfe)\n",
    "print(\"Finally selected features for training = \", rfe_cols)\n",
    "\n",
    "# percentage reduction of features from the actual number of features\n",
    "p_reduced_features_rfe = int((n_features - n_features_rfe)*100/n_features)\n",
    "print(\"Number of features reduced after Variance Thresholding and RFE= \", n_features - n_features_rfe)\n",
    "print(\"Percentage of total features reduced = \", p_reduced_features_rfe, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150654, 60) (37664, 60)\n"
     ]
    }
   ],
   "source": [
    "# keeping on the selected features from lower variance features removal and RFE\n",
    "# for cross-validation\n",
    "X_train = X_train[rfe_cols]\n",
    "X_test = X_test[rfe_cols]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Gradient Boosting Regressor without target transformation\n",
    "5-fold cross-validation with regression metric as MAE. MAE lower is better. Also I am doing a grid search by varying the max_depth from 6 to 10. I also varied the n_estimators and the learning_rate. For lower MAE, lower runtime, and a stable model, from my observation in this project, varying the max_depth will be very effective.\n",
    "<br> Don't confuse by seeing the MAE as negative, because scikit-learn grid-search API try to maximize the scoring function, Thus the regression metric is negative. That means neg_mean_absolute_error greater is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  19.29898193279902\n"
     ]
    }
   ],
   "source": [
    "model_GB_train_MAE, model_GB_test_MAE, model_GB_cv_MAE_df = error_comparison_without_target_transformation(X_train, \n",
    "                                                                                                           y_train, \n",
    "                                                                                                           X_test, \n",
    "                                                                                                           y_test,\n",
    "                                                                                        np.arange(6,11,1).tolist(),\n",
    "                                                                                       'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth =  [6, 7, 8, 9, 10]\n",
      "Training MAE =  [1203.49, 1199.83, 1198.39, 1202.94, 1207.02]\n",
      "Testing MAE =  [1188.26, 1183.65, 1184.47, 1184.85, 1188.37]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__learning_rate</th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_regressor__n_estimators</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>-1204.268472</td>\n",
       "      <td>-1206.008693</td>\n",
       "      <td>-1216.293793</td>\n",
       "      <td>-1193.607667</td>\n",
       "      <td>-1197.284662</td>\n",
       "      <td>-1203.492657</td>\n",
       "      <td>7.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>-1200.842763</td>\n",
       "      <td>-1204.859558</td>\n",
       "      <td>-1211.686317</td>\n",
       "      <td>-1188.592686</td>\n",
       "      <td>-1193.158340</td>\n",
       "      <td>-1199.827933</td>\n",
       "      <td>8.218061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>-1199.379367</td>\n",
       "      <td>-1200.381668</td>\n",
       "      <td>-1213.758261</td>\n",
       "      <td>-1187.240130</td>\n",
       "      <td>-1191.166104</td>\n",
       "      <td>-1198.385106</td>\n",
       "      <td>9.139291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>-1207.710372</td>\n",
       "      <td>-1205.188686</td>\n",
       "      <td>-1215.492237</td>\n",
       "      <td>-1190.929167</td>\n",
       "      <td>-1195.370406</td>\n",
       "      <td>-1202.938174</td>\n",
       "      <td>8.796937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1211.042375</td>\n",
       "      <td>-1209.898540</td>\n",
       "      <td>-1222.210277</td>\n",
       "      <td>-1194.590352</td>\n",
       "      <td>-1197.355267</td>\n",
       "      <td>-1207.019362</td>\n",
       "      <td>10.031084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_regressor__learning_rate param_regressor__max_depth  \\\n",
       "0                            0.1                          6   \n",
       "0                            0.1                          7   \n",
       "0                            0.1                          8   \n",
       "0                            0.1                          9   \n",
       "0                            0.1                         10   \n",
       "\n",
       "  param_regressor__n_estimators  split0_test_score  split1_test_score  \\\n",
       "0                           100       -1204.268472       -1206.008693   \n",
       "0                           100       -1200.842763       -1204.859558   \n",
       "0                           100       -1199.379367       -1200.381668   \n",
       "0                           100       -1207.710372       -1205.188686   \n",
       "0                           100       -1211.042375       -1209.898540   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0       -1216.293793       -1193.607667       -1197.284662     -1203.492657   \n",
       "0       -1211.686317       -1188.592686       -1193.158340     -1199.827933   \n",
       "0       -1213.758261       -1187.240130       -1191.166104     -1198.385106   \n",
       "0       -1215.492237       -1190.929167       -1195.370406     -1202.938174   \n",
       "0       -1222.210277       -1194.590352       -1197.355267     -1207.019362   \n",
       "\n",
       "   std_test_score  \n",
       "0        7.836500  \n",
       "0        8.218061  \n",
       "0        9.139291  \n",
       "0        8.796937  \n",
       "0       10.031084  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"max_depth = \", np.arange(6,11,1).tolist())\n",
    "print(\"Training MAE = \", model_GB_train_MAE)\n",
    "print(\"Testing MAE = \", model_GB_test_MAE)\n",
    "display(model_GB_cv_MAE_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Gradient Boosting Regressor with target transformation\n",
    "\n",
    "5-fold cross-validation with regression scoring metric as MAE including a grid search by varying the max_depth from 6 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  19.277014875411986\n"
     ]
    }
   ],
   "source": [
    "model_GB_TT_train_MAE, model_GB_TT_test_MAE, model_GB_TT_cv_MAE_df = error_comparison_with_target_transformation(X_train, \n",
    "                                                                                       y_train, \n",
    "                                                                                       X_test, \n",
    "                                                                                       y_test,\n",
    "                                                                                        np.arange(6,11,1).tolist(),\n",
    "                                                                                       'neg_mean_absolute_error',\n",
    "                                                                                        PowerTransformer(method='box-cox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth =  [6, 7, 8, 9, 10]\n",
      "Training MAE =  [1167.87, 1165.79, 1167.17, 1169.82, 1175.09]\n",
      "Testing MAE =  [1152.84, 1147.63, 1150.34, 1150.97, 1158.15]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_TargetTransformed__regressor__learning_rate</th>\n",
       "      <th>param_TargetTransformed__regressor__max_depth</th>\n",
       "      <th>param_TargetTransformed__regressor__n_estimators</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>-1175.827769</td>\n",
       "      <td>-1163.489154</td>\n",
       "      <td>-1187.681484</td>\n",
       "      <td>-1157.290311</td>\n",
       "      <td>-1155.080225</td>\n",
       "      <td>-1167.873789</td>\n",
       "      <td>12.251701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>-1175.308748</td>\n",
       "      <td>-1162.877896</td>\n",
       "      <td>-1183.341543</td>\n",
       "      <td>-1156.651419</td>\n",
       "      <td>-1150.785780</td>\n",
       "      <td>-1165.793077</td>\n",
       "      <td>11.964813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>-1176.164658</td>\n",
       "      <td>-1163.068071</td>\n",
       "      <td>-1183.355053</td>\n",
       "      <td>-1158.394657</td>\n",
       "      <td>-1154.890990</td>\n",
       "      <td>-1167.174686</td>\n",
       "      <td>10.839430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>-1175.398816</td>\n",
       "      <td>-1169.963832</td>\n",
       "      <td>-1187.385051</td>\n",
       "      <td>-1160.562629</td>\n",
       "      <td>-1155.811963</td>\n",
       "      <td>-1169.824458</td>\n",
       "      <td>11.149877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1181.672453</td>\n",
       "      <td>-1177.241835</td>\n",
       "      <td>-1193.042240</td>\n",
       "      <td>-1165.936993</td>\n",
       "      <td>-1157.574879</td>\n",
       "      <td>-1175.093680</td>\n",
       "      <td>12.335306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_TargetTransformed__regressor__learning_rate  \\\n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "\n",
       "  param_TargetTransformed__regressor__max_depth  \\\n",
       "0                                             6   \n",
       "0                                             7   \n",
       "0                                             8   \n",
       "0                                             9   \n",
       "0                                            10   \n",
       "\n",
       "  param_TargetTransformed__regressor__n_estimators  split0_test_score  \\\n",
       "0                                              100       -1175.827769   \n",
       "0                                              100       -1175.308748   \n",
       "0                                              100       -1176.164658   \n",
       "0                                              100       -1175.398816   \n",
       "0                                              100       -1181.672453   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0       -1163.489154       -1187.681484       -1157.290311       -1155.080225   \n",
       "0       -1162.877896       -1183.341543       -1156.651419       -1150.785780   \n",
       "0       -1163.068071       -1183.355053       -1158.394657       -1154.890990   \n",
       "0       -1169.963832       -1187.385051       -1160.562629       -1155.811963   \n",
       "0       -1177.241835       -1193.042240       -1165.936993       -1157.574879   \n",
       "\n",
       "   mean_test_score  std_test_score  \n",
       "0     -1167.873789       12.251701  \n",
       "0     -1165.793077       11.964813  \n",
       "0     -1167.174686       10.839430  \n",
       "0     -1169.824458       11.149877  \n",
       "0     -1175.093680       12.335306  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"max_depth = \", np.arange(6,11,1).tolist())\n",
    "print(\"Training MAE = \", model_GB_TT_train_MAE)\n",
    "print(\"Testing MAE = \", model_GB_TT_test_MAE)\n",
    "display(model_GB_TT_cv_MAE_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Boosting Regressor with target transformation\n",
    "\n",
    "5-fold cross-validation with regression scoring metric as RMSE including a grid search by varying the max_depth from 6 to 10.\n",
    "<br> Don't confuse by seeing the RMSE as negative, because scikit-learn grid-search API try to maximize the scoring function, Thus the regression metric is negative. That means neg_root_mean_squared_error greater is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  18.989579844474793\n"
     ]
    }
   ],
   "source": [
    "model_GB_TT_train_RMSE, model_GB_TT_test_RMSE, model_GB_TT_cv_RMSE_df = error_comparison_with_target_transformation(X_train, \n",
    "                                                                                       y_train, \n",
    "                                                                                       X_test, \n",
    "                                                                                       y_test,\n",
    "                                                                                        np.arange(6,11,1).tolist(),\n",
    "                                                                                       'neg_root_mean_squared_error',\n",
    "                                                                                        PowerTransformer(method='box-cox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth =  [6, 7, 8, 9, 10]\n",
      "Training RMSE =  [1997.72, 1984.79, 2006.45, 2003.77, 2019.32]\n",
      "Testing RMSE =  [1916.95, 1917.04, 1926.68, 1925.18, 1942.58]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_TargetTransformed__regressor__learning_rate</th>\n",
       "      <th>param_TargetTransformed__regressor__max_depth</th>\n",
       "      <th>param_TargetTransformed__regressor__n_estimators</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>-2023.042548</td>\n",
       "      <td>-1944.390399</td>\n",
       "      <td>-2079.642916</td>\n",
       "      <td>-1948.704042</td>\n",
       "      <td>-1992.832547</td>\n",
       "      <td>-1997.722491</td>\n",
       "      <td>50.245583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>-2014.080240</td>\n",
       "      <td>-1936.747748</td>\n",
       "      <td>-2067.597578</td>\n",
       "      <td>-1946.346000</td>\n",
       "      <td>-1959.195386</td>\n",
       "      <td>-1984.793390</td>\n",
       "      <td>49.307396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>-2052.463466</td>\n",
       "      <td>-1947.453409</td>\n",
       "      <td>-2080.033920</td>\n",
       "      <td>-1955.908517</td>\n",
       "      <td>-1996.405280</td>\n",
       "      <td>-2006.452918</td>\n",
       "      <td>52.283397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>-2006.793771</td>\n",
       "      <td>-1964.543760</td>\n",
       "      <td>-2084.722519</td>\n",
       "      <td>-1963.119208</td>\n",
       "      <td>-1999.653428</td>\n",
       "      <td>-2003.766537</td>\n",
       "      <td>44.205394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-2035.819475</td>\n",
       "      <td>-1979.836581</td>\n",
       "      <td>-2103.702162</td>\n",
       "      <td>-1972.797365</td>\n",
       "      <td>-2004.460224</td>\n",
       "      <td>-2019.323161</td>\n",
       "      <td>47.616574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_TargetTransformed__regressor__learning_rate  \\\n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "0                                               0.1   \n",
       "\n",
       "  param_TargetTransformed__regressor__max_depth  \\\n",
       "0                                             6   \n",
       "0                                             7   \n",
       "0                                             8   \n",
       "0                                             9   \n",
       "0                                            10   \n",
       "\n",
       "  param_TargetTransformed__regressor__n_estimators  split0_test_score  \\\n",
       "0                                              100       -2023.042548   \n",
       "0                                              100       -2014.080240   \n",
       "0                                              100       -2052.463466   \n",
       "0                                              100       -2006.793771   \n",
       "0                                              100       -2035.819475   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0       -1944.390399       -2079.642916       -1948.704042       -1992.832547   \n",
       "0       -1936.747748       -2067.597578       -1946.346000       -1959.195386   \n",
       "0       -1947.453409       -2080.033920       -1955.908517       -1996.405280   \n",
       "0       -1964.543760       -2084.722519       -1963.119208       -1999.653428   \n",
       "0       -1979.836581       -2103.702162       -1972.797365       -2004.460224   \n",
       "\n",
       "   mean_test_score  std_test_score  \n",
       "0     -1997.722491       50.245583  \n",
       "0     -1984.793390       49.307396  \n",
       "0     -2006.452918       52.283397  \n",
       "0     -2003.766537       44.205394  \n",
       "0     -2019.323161       47.616574  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"max_depth = \", np.arange(6,11,1).tolist())\n",
    "print(\"Training RMSE = \", model_GB_TT_train_RMSE)\n",
    "print(\"Testing RMSE = \", model_GB_TT_test_RMSE)\n",
    "display(model_GB_TT_cv_RMSE_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cross-validation results\n",
    "model_GB_cv_MAE_df.to_csv(\"model_GB_cv_MAE_df.csv\", index=False)\n",
    "model_GB_TT_cv_MAE_df.to_csv(\"model_GB_TT_cv_MAE_df.csv\", index=False)\n",
    "model_GB_TT_cv_RMSE_df.to_csv(\"model_GB_TT_cv_RMSE_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a DataFrame for the MAE results\n",
    "output = pd.DataFrame({'max_depth': np.arange(6,11,1).tolist(),\n",
    "                      'train_MAE': model_GB_train_MAE,\n",
    "                      'test_MAE': model_GB_test_MAE,\n",
    "                      'TT_train_MAE': model_GB_TT_train_MAE,\n",
    "                      'TT_test_MAE': model_GB_TT_test_MAE})\n",
    "\n",
    "display(output)\n",
    "\n",
    "# saving the results\n",
    "output.to_csv(\"regression_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_MAE</th>\n",
       "      <th>test_MAE</th>\n",
       "      <th>TT_train_MAE</th>\n",
       "      <th>TT_test_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1203.49</td>\n",
       "      <td>1188.26</td>\n",
       "      <td>1167.87</td>\n",
       "      <td>1152.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>1183.65</td>\n",
       "      <td>1165.79</td>\n",
       "      <td>1147.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1198.39</td>\n",
       "      <td>1184.47</td>\n",
       "      <td>1167.17</td>\n",
       "      <td>1150.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1202.94</td>\n",
       "      <td>1184.85</td>\n",
       "      <td>1169.82</td>\n",
       "      <td>1150.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1207.02</td>\n",
       "      <td>1188.37</td>\n",
       "      <td>1175.09</td>\n",
       "      <td>1158.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_MAE  test_MAE  TT_train_MAE  TT_test_MAE\n",
       "0          6    1203.49   1188.26       1167.87      1152.84\n",
       "1          7    1199.83   1183.65       1165.79      1147.63\n",
       "2          8    1198.39   1184.47       1167.17      1150.34\n",
       "3          9    1202.94   1184.85       1169.82      1150.97\n",
       "4         10    1207.02   1188.37       1175.09      1158.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reading the MAE results in a dataframe\n",
    "regression_metrics = pd.read_csv(\"regression_metrics.csv\")\n",
    "display(regression_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(regression_metrics.max_depth, regression_metrics.train_MAE, label='train', marker='o', color='b')\n",
    "plt.plot(regression_metrics.max_depth, regression_metrics.test_MAE, label='test', marker='o', color='r')\n",
    "plt.legend()\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.title(\"Fig 01: max_depth vs MAE at Gradient Boosting \\n without target transformation\")\n",
    "plt.xticks(np.arange(6,11,1).tolist())\n",
    "plt.yticks(np.arange(1000,1401,100).tolist())\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(regression_metrics.max_depth, regression_metrics.TT_train_MAE, label='train', marker='o', color='b')\n",
    "plt.plot(regression_metrics.max_depth, regression_metrics.TT_test_MAE, label='test', marker='o', color='r')\n",
    "plt.legend()\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.title(\"Fig 02: max_depth vs MAE at Gradient Boosting \\n with target transformation\")\n",
    "plt.xticks(np.arange(6,11,1).tolist())\n",
    "plt.yticks(np.arange(1000,1401,100).tolist())\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(regression_metrics.max_depth, model_GB_TT_train_RMSE, label='train', marker='o', color='b')\n",
    "plt.plot(regression_metrics.max_depth, model_GB_TT_test_RMSE, label='test', marker='o', color='r')\n",
    "plt.legend()\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Fig 03: max_depth vs RMSE at Gradient Boosting \\n with target transformation\")\n",
    "plt.xticks(np.arange(6,11,1).tolist())\n",
    "plt.yticks(np.arange(1000,2201,100).tolist())\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig 01: max_depth vs MAE at Gradient Boosting Regressor without target transformation\n",
    "\n",
    "From the above Fig 01, the lowest training MAE is 1198.39 and the lowest testing MAE is 1183.65.\n",
    "<br>For the different values of max_depth, \n",
    "<br>the standard deviation of the MAE at the train set and the test set are respectively 3 and 2.\n",
    "<br>It seems the model is quite stable. The training and testing MAE are not varying drastically.\n",
    "\n",
    "Fig 02: max_depth vs MAE at Gradient Boosting Regressor with target transformation\n",
    "\n",
    "From the above Fig 02, the lowest training MAE is 1165.79 and the lowest testing MAE is 1147.63.\n",
    "If we look at the dataframe of the grid search, for the different values of max_depth, \n",
    "<br>the standard deviation of the MAE at the train set and the test set are respectively 3.24 and 3.5\n",
    "<br>It ensures the model is not overfitting or underfitting. The training and testing MAE for different hyperparameter settings are very close to each other.\n",
    "\n",
    "Comparing Fig 01 and Fig 02, and their training & testing MAE, it's confirmed that - target transformation has improved the model performance.\n",
    "\n",
    "Fig 03: max_depth vs RMSE at Gradient Boosting Regressor with target transformation\n",
    "\n",
    "From the above Fig 03, the lowest training RMSE is 1984.79 and the lowest testing RMSE is 1916.95.\n",
    "<br>For the different values of max_depth, \n",
    "<br>the standard deviation of the RMSE at the train set and the test set are respectively 11.3 and 9.36.\n",
    "<br>From this scenario, It also seems the model is quite stable. The training and testing RMSE are not varying drastically.\n",
    "\n",
    "Comparing Fig 02 and Fig 03, and their training & testing error, the best hyperparameters are -\n",
    "<br>n_estimators=100\n",
    "<br>learning_rate=0.1\n",
    "<br>max_depth = 7\n",
    "\n",
    "For each individual model,\n",
    "<br>Number of folds in cross-validation = 5\n",
    "<br>Number of hyperparamters = 5 (max_depth from 6 to 10)\n",
    "<br>Number of iteration  = 5*5 = 25\n",
    "<br>Total runtime = 19 mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GB = GBRegressor_with_target_transformation(X_train, y_train, \n",
    "                                                  [100], [7], [0.1], \n",
    "                                                  'neg_mean_absolute_error',\n",
    "                                                  PowerTransformer(method='box-cox'))\n",
    "\n",
    "# saving the best model\n",
    "pickle.dump(model_GB, open(\"model_GB.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model for prediction\n",
    "model_GB = pickle.load(open(\"model_GB.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and submission file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with the finally selected features\n",
    "predictions = model_GB.predict(test[rfe_cols])\n",
    "\n",
    "# adding the predictions in the test dataFrame to get the index 'id'\n",
    "test['loss'] = predictions\n",
    "\n",
    "# separating the predicted 'loss' in a dataFrame\n",
    "submission = test[['loss']]\n",
    "display(submission.head())\n",
    "\n",
    "# Generating submission .csv file\n",
    "submission.to_csv(\"submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
